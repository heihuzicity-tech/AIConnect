// AI Chat Handler for different AI models
import { createClient } from 'npm:@supabase/supabase-js@2'
import * as kv from './kv_store.tsx'

interface ChatRequest {
  model: string
  message: string
  feedItems?: any[]
  filters?: any
  settings?: {
    temperature: number
    maxTokens: number
    systemPrompt: string
    apiKeys: Record<string, string>
  }
}

interface ChatResponse {
  response: string
  model: string
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
}

// OpenAI APIè°ƒç”¨
async function callOpenAI(request: ChatRequest): Promise<ChatResponse> {
  const apiKey = request.settings?.apiKeys[request.model] || Deno.env.get('OPENAI_API_KEY')
  
  if (!apiKey) {
    throw new Error('OpenAI API key not configured')
  }

  const systemPrompt = request.settings?.systemPrompt || `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIä¿¡æ¯åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ†æå’Œç†è§£AIè¡Œä¸šåŠ¨æ€ã€‚`
  
  // æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
  let contextInfo = ''
  if (request.feedItems && request.feedItems.length > 0) {
    contextInfo = `\n\nå½“å‰ä¿¡æ¯æµæ•°æ®æ‘˜è¦ï¼š\n${request.feedItems.slice(0, 5).map(item => 
      `â€¢ ${item.company}: ${item.title}`
    ).join('\n')}`
  }

  const messages = [
    {
      role: 'system',
      content: systemPrompt + contextInfo
    },
    {
      role: 'user',
      content: request.message
    }
  ]

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: request.model,
      messages,
      temperature: request.settings?.temperature || 0.7,
      max_tokens: request.settings?.maxTokens || 1000
    })
  })

  if (!response.ok) {
    const error = await response.text()
    throw new Error(`OpenAI API error: ${response.status} - ${error}`)
  }

  const data = await response.json()
  
  return {
    response: data.choices[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚',
    model: request.model,
    usage: data.usage ? {
      promptTokens: data.usage.prompt_tokens,
      completionTokens: data.usage.completion_tokens,
      totalTokens: data.usage.total_tokens
    } : undefined
  }
}

// Anthropic Claude APIè°ƒç”¨
async function callClaude(request: ChatRequest): Promise<ChatResponse> {
  const apiKey = request.settings?.apiKeys[request.model] || Deno.env.get('ANTHROPIC_API_KEY')
  
  if (!apiKey) {
    throw new Error('Anthropic API key not configured')
  }

  const systemPrompt = request.settings?.systemPrompt || `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIä¿¡æ¯åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ†æå’Œç†è§£AIè¡Œä¸šåŠ¨æ€ã€‚`
  
  // æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
  let contextInfo = ''
  if (request.feedItems && request.feedItems.length > 0) {
    contextInfo = `\n\nå½“å‰ä¿¡æ¯æµæ•°æ®æ‘˜è¦ï¼š\n${request.feedItems.slice(0, 5).map(item => 
      `â€¢ ${item.company}: ${item.title}`
    ).join('\n')}`
  }

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model: request.model,
      max_tokens: request.settings?.maxTokens || 1000,
      temperature: request.settings?.temperature || 0.7,
      system: systemPrompt + contextInfo,
      messages: [
        {
          role: 'user',
          content: request.message
        }
      ]
    })
  })

  if (!response.ok) {
    const error = await response.text()
    throw new Error(`Anthropic API error: ${response.status} - ${error}`)
  }

  const data = await response.json()
  
  return {
    response: data.content[0]?.text || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚',
    model: request.model,
    usage: data.usage ? {
      promptTokens: data.usage.input_tokens,
      completionTokens: data.usage.output_tokens,
      totalTokens: data.usage.input_tokens + data.usage.output_tokens
    } : undefined
  }
}

// xAI Grok APIè°ƒç”¨ï¼ˆå‡è®¾çš„APIç«¯ç‚¹ï¼Œå®é™…éœ€è¦æ ¹æ®xAIæ–‡æ¡£è°ƒæ•´ï¼‰
async function callGrok(request: ChatRequest): Promise<ChatResponse> {
  const apiKey = request.settings?.apiKeys[request.model] || Deno.env.get('XAI_API_KEY')
  
  if (!apiKey) {
    throw new Error('xAI API key not configured')
  }

  // æ³¨æ„ï¼šè¿™æ˜¯å‡è®¾çš„APIç«¯ç‚¹ï¼Œå®é™…éœ€è¦æ ¹æ®xAIçš„çœŸå®APIæ–‡æ¡£è°ƒæ•´
  const response = await fetch('https://api.x.ai/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'grok-beta',
      messages: [
        {
          role: 'system',
          content: request.settings?.systemPrompt || 'ä½ æ˜¯Grokï¼Œä¸€ä¸ªæœ‰è¶£ä¸”æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚'
        },
        {
          role: 'user',
          content: request.message
        }
      ],
      temperature: request.settings?.temperature || 0.7,
      max_tokens: request.settings?.maxTokens || 1000
    })
  })

  if (!response.ok) {
    // å¦‚æœGrok APIä¸å¯ç”¨ï¼Œè¿”å›ä¸€ä¸ªæ¨¡æ‹Ÿå“åº”
    return {
      response: `æˆ‘æ˜¯Grokï¼å…³äºä½ çš„é—®é¢˜"${request.message}"ï¼Œæˆ‘è§‰å¾—è¿™æ˜¯ä¸ªå¾ˆæœ‰è¶£çš„è¯é¢˜ã€‚ä¸è¿‡ç›®å‰æˆ‘çš„APIè¿˜åœ¨å¼€å‘ä¸­ï¼Œè¯·ç¨åå†è¯•ã€‚ğŸš€`,
      model: request.model
    }
  }

  const data = await response.json()
  
  return {
    response: data.choices[0]?.message?.content || 'æŠ±æ­‰ï¼ŒGrokæš‚æ—¶æ— æ³•å›å¤ã€‚',
    model: request.model,
    usage: data.usage
  }
}

// ä¸»è¦çš„èŠå¤©å¤„ç†å‡½æ•°
export async function handleAIChat(request: Request): Promise<Response> {
  try {
    const body = await request.json() as ChatRequest
    
    if (!body.message || !body.model) {
      return new Response(JSON.stringify({ 
        error: 'Missing required fields: message and model' 
      }), { 
        status: 400,
        headers: { 'Content-Type': 'application/json' }
      })
    }

    let result: ChatResponse

    // æ ¹æ®æ¨¡å‹ç±»å‹è°ƒç”¨ç›¸åº”çš„API
    if (body.model.includes('gpt')) {
      result = await callOpenAI(body)
    } else if (body.model.includes('claude')) {
      result = await callClaude(body)
    } else if (body.model.includes('grok')) {
      result = await callGrok(body)
    } else {
      throw new Error(`Unsupported model: ${body.model}`)
    }

    // è®°å½•ä½¿ç”¨ç»Ÿè®¡
    try {
      const today = new Date().toISOString().split('T')[0]
      const statsKey = `ai_usage_${today}`
      const currentStats = await kv.get(statsKey) || { totalCalls: 0, totalTokens: 0, models: {} }
      
      currentStats.totalCalls++
      if (result.usage) {
        currentStats.totalTokens += result.usage.totalTokens
      }
      
      if (!currentStats.models[body.model]) {
        currentStats.models[body.model] = { calls: 0, tokens: 0 }
      }
      currentStats.models[body.model].calls++
      if (result.usage) {
        currentStats.models[body.model].tokens += result.usage.totalTokens
      }
      
      await kv.set(statsKey, currentStats, { ttl: 86400 * 7 }) // ä¿å­˜7å¤©
    } catch (error) {
      console.error('Error saving AI usage stats:', error)
    }

    return new Response(JSON.stringify(result), {
      headers: { 'Content-Type': 'application/json' }
    })

  } catch (error) {
    console.error('AI chat error:', error)
    
    return new Response(JSON.stringify({ 
      error: error.message,
      fallbackResponse: 'æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚è¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–ç¨åé‡è¯•ã€‚'
    }), { 
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
}

// è·å–AIä½¿ç”¨ç»Ÿè®¡
export async function getAIUsageStats(): Promise<Response> {
  try {
    const today = new Date().toISOString().split('T')[0]
    const statsKey = `ai_usage_${today}`
    const stats = await kv.get(statsKey) || { totalCalls: 0, totalTokens: 0, models: {} }
    
    return new Response(JSON.stringify(stats), {
      headers: { 'Content-Type': 'application/json' }
    })
  } catch (error) {
    console.error('Error getting AI usage stats:', error)
    return new Response(JSON.stringify({ error: error.message }), { 
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
}